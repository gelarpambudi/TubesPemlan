{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Stpip4bZ9mC"
   },
   "source": [
    "Percobaan ketiga dengan transfer learning CNN menggunakan model DenseNet121 </br>\n",
    "Training dilakukan dengan 70 epochs </br>\n",
    "Model yang dihasilkan punya akurasi validasi (test) 94%. Nilai tersebut diperoleh pada epoch ke 67 </br>\n",
    "History dari training disimpan di file historyModelTransferLearning.h5 </br>\n",
    "Training dilakukan di platform Google Colab </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMs_1wc1Z9mG"
   },
   "source": [
    "<h2> ====IMPORT LIBRARY==== </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3742,
     "status": "ok",
     "timestamp": 1575669747113,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "j3JMIB_XZ9mI",
    "outputId": "29afb499-9d92-4422-d3e6-2c9a9a4956f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow\n",
    "from tensorflow.keras import optimizers, regularizers, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D, BatchNormalization\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "from tensorflow.keras.applications import densenet\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35550,
     "status": "ok",
     "timestamp": 1575655990147,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "agJUGbiHaarK",
    "outputId": "67bec23f-7b2f-4c21-f802-6bdbdfe6be0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1_7tkI7Z9mR"
   },
   "source": [
    "<h2>====DATASET INPUT====</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1033,
     "status": "ok",
     "timestamp": 1575656034610,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "yIV83SZEatq2",
    "outputId": "d8e585e4-956e-4099-a3ec-41168da2df82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/TubesPemlan/TubesPemlan\n"
     ]
    }
   ],
   "source": [
    "%cd gdrive/My\\ Drive/TubesPemlan/TubesPemlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4683,
     "status": "ok",
     "timestamp": 1575656043070,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "H8zGhwy9Z9mS",
    "outputId": "206777f6-69d1-4daa-f5e7-912daa6a6cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah dataset: 2527\n"
     ]
    }
   ],
   "source": [
    "path = \"dataset-resized\"\n",
    "listImage = glob.glob(os.path.join(path, '*/*.jpg'))\n",
    "print(\"Jumlah dataset: \" + str(len(listImage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8p2RlichZ9mY"
   },
   "source": [
    "<h2> ====IMAGE AUGMENTATION==== </h2>\n",
    "\n",
    "Membuat image augmentation pada dataset yang sudah ada untuk memperbanyak jumlah dataset</br>\n",
    "Membagi dataset yang ada menjadi dataset untuk training dan test </br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1421,
     "status": "ok",
     "timestamp": 1575656048832,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "PpsCrEeuZ9ma",
    "outputId": "09a4e45f-7d18-410b-8678-1454bfb038e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2276 images belonging to 6 classes.\n",
      "Found 251 images belonging to 6 classes.\n",
      "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator(horizontal_flip=True,\n",
    "                          validation_split=0.1,\n",
    "                          rescale=1./255,\n",
    "                          shear_range=0.2,\n",
    "                          zoom_range=0.2,\n",
    "                          width_shift_range=0.2,\n",
    "                          height_shift_range=0.2)\n",
    "\n",
    "test = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "train_generator = train.flow_from_directory(path, \n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            subset=\"training\")\n",
    "\n",
    "test_generator = test.flow_from_directory(path,\n",
    "                                          target_size=(224,224),\n",
    "                                          batch_size=32,\n",
    "                                          class_mode=\"categorical\",\n",
    "                                          subset=\"validation\")\n",
    "\n",
    "#label untuk image\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13639,
     "status": "ok",
     "timestamp": 1575656067615,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "nBfnrMP4Z9mf",
    "outputId": "fc30e492-7b84-4582-faf8-9384b1ff32ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 224, 224, 3), (32, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for img,label in train_generator:\n",
    "    break\n",
    "img.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53lpes6pZ9ml"
   },
   "outputs": [],
   "source": [
    "Labels = '\\n'.join(sorted(train_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0RLQUPpZ9mq"
   },
   "source": [
    "<h2> ====CNN (Convolutional Neural Network)==== </h2>\n",
    "\n",
    "Load model dari DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18590,
     "status": "ok",
     "timestamp": 1575656097754,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "qRo-XRbhZ9mq",
    "outputId": "18eba43a-19b7-44af-a6b4-9060d2c3f9cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "base_model = densenet.DenseNet121(include_top=False,\n",
    "                                  weights=\"imagenet\",\n",
    "                                  input_tensor=None,\n",
    "                                  input_shape=(224,224,3),\n",
    "                                  pooling=\"max\")\n",
    "\n",
    "x = base_model.output\n",
    "x = Dense(256, activation=\"elu\", kernel_regularizer=regularizers.l2(0.1))(x)\n",
    "x = Dropout(0.6)(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1cSroJcZ9mv"
   },
   "outputs": [],
   "source": [
    "#menyimpan model\n",
    "modelFile = \"modelConfigTransferLearning.h5\"\n",
    "checkpoint1 = ModelCheckpoint(modelFile, monitor=\"val_acc\", verbose=1, save_best_only=True, mode=\"max\")\n",
    "callback_list = [checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJyEdFO1Z9m0"
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdbT0sRLZ9m6"
   },
   "source": [
    "<h2>====TRAINING====</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3723298,
     "status": "ok",
     "timestamp": 1575661950391,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "Z6pMzXYxZ9m8",
    "outputId": "649a036d-996e-420a-ff12-5cf63691f7c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 31.4358 - acc: 0.7674Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 30.9561 - acc: 0.7610\n",
      "Epoch 00001: val_acc improved from -inf to 0.76096, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 166s 2s/step - loss: 31.4292 - acc: 0.7685 - val_loss: 30.9561 - val_acc: 0.7610\n",
      "Epoch 2/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 30.5181 - acc: 0.7790Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 30.1322 - acc: 0.7729\n",
      "Epoch 00002: val_acc improved from 0.76096 to 0.77291, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 64s 895ms/step - loss: 30.5151 - acc: 0.7781 - val_loss: 30.1322 - val_acc: 0.7729\n",
      "Epoch 3/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 29.6278 - acc: 0.7932Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 29.1036 - acc: 0.8327\n",
      "Epoch 00003: val_acc improved from 0.77291 to 0.83267, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 64s 892ms/step - loss: 29.6218 - acc: 0.7931 - val_loss: 29.1036 - val_acc: 0.8327\n",
      "Epoch 4/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 28.7234 - acc: 0.8316Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 28.2770 - acc: 0.8327\n",
      "Epoch 00004: val_acc did not improve from 0.83267\n",
      "72/72 [==============================] - 61s 854ms/step - loss: 28.7199 - acc: 0.8308 - val_loss: 28.2770 - val_acc: 0.8327\n",
      "Epoch 5/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 27.9171 - acc: 0.8302Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 27.6178 - acc: 0.7928\n",
      "Epoch 00005: val_acc did not improve from 0.83267\n",
      "72/72 [==============================] - 61s 850ms/step - loss: 27.9131 - acc: 0.8291 - val_loss: 27.6178 - val_acc: 0.7928\n",
      "Epoch 6/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 27.1210 - acc: 0.8418Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 27.3455 - acc: 0.6295\n",
      "Epoch 00006: val_acc did not improve from 0.83267\n",
      "72/72 [==============================] - 62s 855ms/step - loss: 27.1198 - acc: 0.8405 - val_loss: 27.3455 - val_acc: 0.6295\n",
      "Epoch 7/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 26.3606 - acc: 0.8302Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 25.9370 - acc: 0.8606\n",
      "Epoch 00007: val_acc improved from 0.83267 to 0.86056, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 65s 896ms/step - loss: 26.3572 - acc: 0.8295 - val_loss: 25.9370 - val_acc: 0.8606\n",
      "Epoch 8/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 25.6146 - acc: 0.8400Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 25.2008 - acc: 0.8406\n",
      "Epoch 00008: val_acc did not improve from 0.86056\n",
      "72/72 [==============================] - 61s 854ms/step - loss: 25.6092 - acc: 0.8401 - val_loss: 25.2008 - val_acc: 0.8406\n",
      "Epoch 9/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 24.8418 - acc: 0.8627Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 24.4848 - acc: 0.8606\n",
      "Epoch 00009: val_acc did not improve from 0.86056\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 24.8369 - acc: 0.8634 - val_loss: 24.4848 - val_acc: 0.8606\n",
      "Epoch 10/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 24.1463 - acc: 0.8623Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 23.7355 - acc: 0.8964\n",
      "Epoch 00010: val_acc improved from 0.86056 to 0.89641, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 64s 886ms/step - loss: 24.1432 - acc: 0.8603 - val_loss: 23.7355 - val_acc: 0.8964\n",
      "Epoch 11/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 23.4646 - acc: 0.8743Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 23.0689 - acc: 0.8845\n",
      "Epoch 00011: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 23.4588 - acc: 0.8748 - val_loss: 23.0689 - val_acc: 0.8845\n",
      "Epoch 12/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 22.7746 - acc: 0.8725Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 20s - loss: 22.5715 - acc: 0.8048\n",
      "Epoch 00012: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 61s 854ms/step - loss: 22.7733 - acc: 0.8708 - val_loss: 22.5715 - val_acc: 0.8048\n",
      "Epoch 13/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 22.1286 - acc: 0.8717Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 19s - loss: 21.7980 - acc: 0.8765\n",
      "Epoch 00013: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 22.1251 - acc: 0.8717 - val_loss: 21.7980 - val_acc: 0.8765\n",
      "Epoch 14/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 21.4998 - acc: 0.8873Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 21.2526 - acc: 0.8645\n",
      "Epoch 00014: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 21.4982 - acc: 0.8862 - val_loss: 21.2526 - val_acc: 0.8645\n",
      "Epoch 15/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 20.9240 - acc: 0.8757Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 20.5937 - acc: 0.8845\n",
      "Epoch 00015: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 20.9208 - acc: 0.8761 - val_loss: 20.5937 - val_acc: 0.8845\n",
      "Epoch 16/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 20.3066 - acc: 0.8886Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 20.0010 - acc: 0.8845\n",
      "Epoch 00016: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 62s 856ms/step - loss: 20.3005 - acc: 0.8893 - val_loss: 20.0010 - val_acc: 0.8845\n",
      "Epoch 17/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 19.7284 - acc: 0.8917Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 19.6028 - acc: 0.8167\n",
      "Epoch 00017: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 61s 851ms/step - loss: 19.7230 - acc: 0.8928 - val_loss: 19.6028 - val_acc: 0.8167\n",
      "Epoch 18/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 19.1268 - acc: 0.9095Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 18.9290 - acc: 0.8884\n",
      "Epoch 00018: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 61s 850ms/step - loss: 19.1244 - acc: 0.9091 - val_loss: 18.9290 - val_acc: 0.8884\n",
      "Epoch 19/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 18.6127 - acc: 0.8953Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 18.3910 - acc: 0.8845\n",
      "Epoch 00019: val_acc did not improve from 0.89641\n",
      "72/72 [==============================] - 62s 855ms/step - loss: 18.6086 - acc: 0.8954 - val_loss: 18.3910 - val_acc: 0.8845\n",
      "Epoch 20/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 18.0810 - acc: 0.9078Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 17.8326 - acc: 0.9084\n",
      "Epoch 00020: val_acc improved from 0.89641 to 0.90837, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 64s 890ms/step - loss: 18.0751 - acc: 0.9086 - val_loss: 17.8326 - val_acc: 0.9084\n",
      "Epoch 21/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 17.5651 - acc: 0.9064Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 19s - loss: 17.3704 - acc: 0.8845\n",
      "Epoch 00021: val_acc did not improve from 0.90837\n",
      "72/72 [==============================] - 62s 856ms/step - loss: 17.5606 - acc: 0.9064 - val_loss: 17.3704 - val_acc: 0.8845\n",
      "Epoch 22/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 17.0463 - acc: 0.9207Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 16.8700 - acc: 0.8924\n",
      "Epoch 00022: val_acc did not improve from 0.90837\n",
      "72/72 [==============================] - 61s 851ms/step - loss: 17.0433 - acc: 0.9205 - val_loss: 16.8700 - val_acc: 0.8924\n",
      "Epoch 23/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 16.5535 - acc: 0.9260Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 16.3679 - acc: 0.9203\n",
      "Epoch 00023: val_acc improved from 0.90837 to 0.92032, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 64s 892ms/step - loss: 16.5485 - acc: 0.9266 - val_loss: 16.3679 - val_acc: 0.9203\n",
      "Epoch 24/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 16.0863 - acc: 0.9345Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 16.1200 - acc: 0.8167\n",
      "Epoch 00024: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 62s 855ms/step - loss: 16.0842 - acc: 0.9345 - val_loss: 16.1200 - val_acc: 0.8167\n",
      "Epoch 25/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 15.6289 - acc: 0.9287Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 19s - loss: 15.4953 - acc: 0.8964\n",
      "Epoch 00025: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 853ms/step - loss: 15.6279 - acc: 0.9279 - val_loss: 15.4953 - val_acc: 0.8964\n",
      "Epoch 26/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 15.1814 - acc: 0.9296Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 20s - loss: 14.9950 - acc: 0.9124\n",
      "Epoch 00026: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 62s 856ms/step - loss: 15.1804 - acc: 0.9293 - val_loss: 14.9950 - val_acc: 0.9124\n",
      "Epoch 27/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 14.7491 - acc: 0.9385Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 14.6175 - acc: 0.8805\n",
      "Epoch 00027: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 62s 855ms/step - loss: 14.7467 - acc: 0.9385 - val_loss: 14.6175 - val_acc: 0.8805\n",
      "Epoch 28/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 14.3318 - acc: 0.9327Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 14.2101 - acc: 0.8964\n",
      "Epoch 00028: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 853ms/step - loss: 14.3287 - acc: 0.9328 - val_loss: 14.2101 - val_acc: 0.8964\n",
      "Epoch 29/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 13.9197 - acc: 0.9412Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 13.8214 - acc: 0.8964\n",
      "Epoch 00029: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 849ms/step - loss: 13.9176 - acc: 0.9411 - val_loss: 13.8214 - val_acc: 0.8964\n",
      "Epoch 30/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 13.5083 - acc: 0.9470Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 13.4024 - acc: 0.9124\n",
      "Epoch 00030: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 854ms/step - loss: 13.5062 - acc: 0.9464 - val_loss: 13.4024 - val_acc: 0.9124\n",
      "Epoch 31/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 13.1241 - acc: 0.9479Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 13.0143 - acc: 0.9203\n",
      "Epoch 00031: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 13.1212 - acc: 0.9477 - val_loss: 13.0143 - val_acc: 0.9203\n",
      "Epoch 32/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 12.7771 - acc: 0.9456Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 12.6801 - acc: 0.8884\n",
      "Epoch 00032: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 850ms/step - loss: 12.7764 - acc: 0.9451 - val_loss: 12.6801 - val_acc: 0.8884\n",
      "Epoch 33/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 12.4065 - acc: 0.9550Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 12.4002 - acc: 0.8606\n",
      "Epoch 00033: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 12.4021 - acc: 0.9556 - val_loss: 12.4002 - val_acc: 0.8606\n",
      "Epoch 34/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 12.0625 - acc: 0.9456Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 12.2826 - acc: 0.8088\n",
      "Epoch 00034: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 62s 855ms/step - loss: 12.0631 - acc: 0.9451 - val_loss: 12.2826 - val_acc: 0.8088\n",
      "Epoch 35/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 11.7017 - acc: 0.9551Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 11.6294 - acc: 0.9163\n",
      "Epoch 00035: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 850ms/step - loss: 11.6977 - acc: 0.9552 - val_loss: 11.6294 - val_acc: 0.9163\n",
      "Epoch 36/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 11.3586 - acc: 0.9537Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 11.3428 - acc: 0.8884\n",
      "Epoch 00036: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 850ms/step - loss: 11.3555 - acc: 0.9539 - val_loss: 11.3428 - val_acc: 0.8884\n",
      "Epoch 37/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 11.0620 - acc: 0.9545Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 10.9826 - acc: 0.9004\n",
      "Epoch 00037: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 853ms/step - loss: 11.0583 - acc: 0.9547 - val_loss: 10.9826 - val_acc: 0.9004\n",
      "Epoch 38/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 10.7386 - acc: 0.9603Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 10.6526 - acc: 0.9163\n",
      "Epoch 00038: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 851ms/step - loss: 10.7348 - acc: 0.9609 - val_loss: 10.6526 - val_acc: 0.9163\n",
      "Epoch 39/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 10.4421 - acc: 0.9519Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 10.3707 - acc: 0.9124\n",
      "Epoch 00039: val_acc did not improve from 0.92032\n",
      "72/72 [==============================] - 61s 851ms/step - loss: 10.4393 - acc: 0.9521 - val_loss: 10.3707 - val_acc: 0.9124\n",
      "Epoch 40/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 10.1325 - acc: 0.9590Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 10.0797 - acc: 0.9283\n",
      "Epoch 00040: val_acc improved from 0.92032 to 0.92829, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 64s 893ms/step - loss: 10.1301 - acc: 0.9591 - val_loss: 10.0797 - val_acc: 0.9283\n",
      "Epoch 41/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.8566 - acc: 0.9639Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 9.8059 - acc: 0.9124\n",
      "Epoch 00041: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 9.8548 - acc: 0.9631 - val_loss: 9.8059 - val_acc: 0.9124\n",
      "Epoch 42/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.5902 - acc: 0.9568Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 9.6509 - acc: 0.8884\n",
      "Epoch 00042: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 848ms/step - loss: 9.5870 - acc: 0.9569 - val_loss: 9.6509 - val_acc: 0.8884\n",
      "Epoch 43/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.3299 - acc: 0.9554Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 9.2550 - acc: 0.9283\n",
      "Epoch 00043: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 850ms/step - loss: 9.3263 - acc: 0.9561 - val_loss: 9.2550 - val_acc: 0.9283\n",
      "Epoch 44/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 9.0544 - acc: 0.9572Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 9.0987 - acc: 0.8884\n",
      "Epoch 00044: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 62s 856ms/step - loss: 9.0528 - acc: 0.9574 - val_loss: 9.0987 - val_acc: 0.8884\n",
      "Epoch 45/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.7820 - acc: 0.9617Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 19s - loss: 8.8214 - acc: 0.9044\n",
      "Epoch 00045: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 853ms/step - loss: 8.7795 - acc: 0.9618 - val_loss: 8.8214 - val_acc: 0.9044\n",
      "Epoch 46/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.5255 - acc: 0.9643Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 8.5994 - acc: 0.9044\n",
      "Epoch 00046: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 62s 854ms/step - loss: 8.5236 - acc: 0.9644 - val_loss: 8.5994 - val_acc: 0.9044\n",
      "Epoch 47/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.2978 - acc: 0.9648Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 8.3043 - acc: 0.9044\n",
      "Epoch 00047: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 8.2963 - acc: 0.9644 - val_loss: 8.3043 - val_acc: 0.9044\n",
      "Epoch 48/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 8.0370 - acc: 0.9733Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 8.0352 - acc: 0.9283\n",
      "Epoch 00048: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 854ms/step - loss: 8.0356 - acc: 0.9732 - val_loss: 8.0352 - val_acc: 0.9283\n",
      "Epoch 49/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.8121 - acc: 0.9742Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 7.8370 - acc: 0.9084\n",
      "Epoch 00049: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 847ms/step - loss: 7.8106 - acc: 0.9745 - val_loss: 7.8370 - val_acc: 0.9084\n",
      "Epoch 50/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.5951 - acc: 0.9733Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 7.6254 - acc: 0.9163\n",
      "Epoch 00050: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 849ms/step - loss: 7.5936 - acc: 0.9732 - val_loss: 7.6254 - val_acc: 0.9163\n",
      "Epoch 51/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.3888 - acc: 0.9693Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 7.4686 - acc: 0.9243\n",
      "Epoch 00051: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 62s 856ms/step - loss: 7.3870 - acc: 0.9697 - val_loss: 7.4686 - val_acc: 0.9243\n",
      "Epoch 52/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 7.1770 - acc: 0.9719Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 7.2256 - acc: 0.9203\n",
      "Epoch 00052: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 851ms/step - loss: 7.1757 - acc: 0.9714 - val_loss: 7.2256 - val_acc: 0.9203\n",
      "Epoch 53/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.9836 - acc: 0.9755Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 7.3200 - acc: 0.8287\n",
      "Epoch 00053: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 62s 855ms/step - loss: 6.9819 - acc: 0.9754 - val_loss: 7.3200 - val_acc: 0.8287\n",
      "Epoch 54/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.7764 - acc: 0.9759Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 6.8452 - acc: 0.9044\n",
      "Epoch 00054: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 6.7752 - acc: 0.9758 - val_loss: 6.8452 - val_acc: 0.9044\n",
      "Epoch 55/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.6315 - acc: 0.9661Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 6.8071 - acc: 0.8446\n",
      "Epoch 00055: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 62s 855ms/step - loss: 6.6303 - acc: 0.9657 - val_loss: 6.8071 - val_acc: 0.8446\n",
      "Epoch 56/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.4110 - acc: 0.9728Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 6.4689 - acc: 0.9004\n",
      "Epoch 00056: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 6.4096 - acc: 0.9728 - val_loss: 6.4689 - val_acc: 0.9004\n",
      "Epoch 57/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.2122 - acc: 0.9795Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 19s - loss: 6.2668 - acc: 0.9203\n",
      "Epoch 00057: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 6.2106 - acc: 0.9798 - val_loss: 6.2668 - val_acc: 0.9203\n",
      "Epoch 58/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 6.0464 - acc: 0.9773Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 6.1229 - acc: 0.9163\n",
      "Epoch 00058: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 853ms/step - loss: 6.0459 - acc: 0.9763 - val_loss: 6.1229 - val_acc: 0.9163\n",
      "Epoch 59/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 5.9139 - acc: 0.9706Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 5.9296 - acc: 0.9124\n",
      "Epoch 00059: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 850ms/step - loss: 5.9120 - acc: 0.9706 - val_loss: 5.9296 - val_acc: 0.9124\n",
      "Epoch 60/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 5.7112 - acc: 0.9742Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 5.7412 - acc: 0.9203\n",
      "Epoch 00060: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 850ms/step - loss: 5.7095 - acc: 0.9745 - val_loss: 5.7412 - val_acc: 0.9203\n",
      "Epoch 61/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 5.5576 - acc: 0.9786Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 5.5940 - acc: 0.9203\n",
      "Epoch 00061: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 849ms/step - loss: 5.5562 - acc: 0.9780 - val_loss: 5.5940 - val_acc: 0.9203\n",
      "Epoch 62/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 5.3811 - acc: 0.9808Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 5.4257 - acc: 0.9203\n",
      "Epoch 00062: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 5.3804 - acc: 0.9807 - val_loss: 5.4257 - val_acc: 0.9203\n",
      "Epoch 63/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 5.2361 - acc: 0.9782Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 5.2880 - acc: 0.9203\n",
      "Epoch 00063: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 5.2344 - acc: 0.9785 - val_loss: 5.2880 - val_acc: 0.9203\n",
      "Epoch 64/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 5.1297 - acc: 0.9755Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 5.2141 - acc: 0.9124\n",
      "Epoch 00064: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 848ms/step - loss: 5.1271 - acc: 0.9758 - val_loss: 5.2141 - val_acc: 0.9124\n",
      "Epoch 65/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.9543 - acc: 0.9768Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 5.0294 - acc: 0.9203\n",
      "Epoch 00065: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 852ms/step - loss: 4.9528 - acc: 0.9772 - val_loss: 5.0294 - val_acc: 0.9203\n",
      "Epoch 66/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.8084 - acc: 0.9831Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 4.8751 - acc: 0.9283\n",
      "Epoch 00066: val_acc did not improve from 0.92829\n",
      "72/72 [==============================] - 61s 849ms/step - loss: 4.8071 - acc: 0.9829 - val_loss: 4.8751 - val_acc: 0.9283\n",
      "Epoch 67/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.6961 - acc: 0.9750Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 4.7209 - acc: 0.9442\n",
      "Epoch 00067: val_acc improved from 0.92829 to 0.94422, saving model to modelConfigTransferLearning.h5\n",
      "72/72 [==============================] - 64s 894ms/step - loss: 4.6944 - acc: 0.9754 - val_loss: 4.7209 - val_acc: 0.9442\n",
      "Epoch 68/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.5405 - acc: 0.9813Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 17s - loss: 4.5993 - acc: 0.9363\n",
      "Epoch 00068: val_acc did not improve from 0.94422\n",
      "72/72 [==============================] - 61s 849ms/step - loss: 4.5391 - acc: 0.9815 - val_loss: 4.5993 - val_acc: 0.9363\n",
      "Epoch 69/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.4085 - acc: 0.9831Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 4.4731 - acc: 0.9402\n",
      "Epoch 00069: val_acc did not improve from 0.94422\n",
      "72/72 [==============================] - 61s 849ms/step - loss: 4.4080 - acc: 0.9829 - val_loss: 4.4731 - val_acc: 0.9402\n",
      "Epoch 70/70\n",
      "71/72 [============================>.] - ETA: 0s - loss: 4.3202 - acc: 0.9764Epoch 1/70\n",
      " 8/72 [==>...........................] - ETA: 18s - loss: 4.3664 - acc: 0.9243\n",
      "Epoch 00070: val_acc did not improve from 0.94422\n",
      "72/72 [==============================] - 61s 851ms/step - loss: 4.3184 - acc: 0.9767 - val_loss: 4.3664 - val_acc: 0.9243\n",
      "CPU times: user 1h 43min 10s, sys: 19min 32s, total: 2h 2min 43s\n",
      "Wall time: 1h 13min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=70,\n",
    "                              steps_per_epoch=len(train_generator),\n",
    "                              validation_data=test_generator,\n",
    "                              validation_steps=len(test_generator),\n",
    "                              callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4631,
     "status": "error",
     "timestamp": 1575669760250,
     "user": {
      "displayName": "Gelar Pambudi Adhiluhung",
      "photoUrl": "",
      "userId": "07333039714321618380"
     },
     "user_tz": -420
    },
    "id": "GErBib_dZ9nB",
    "outputId": "31f9d82f-58a3-492e-bff5-bd82821a4549"
   },
   "outputs": [],
   "source": [
    "#save history ke file\n",
    "with open('historyModelTransferLearning', 'wb') as f :\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Z2OZdMHZ9nG"
   },
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "validation_acc = history.history['val_acc']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "#plot grafik akurasi\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(validation_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "#plot grafik loss\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TubesTransferLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow GPU",
   "language": "python",
   "name": "tubes-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
