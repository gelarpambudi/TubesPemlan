{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percobaan pertama membuat model CNN menggunaka Keras </br>\n",
    "Training dilakukan dengan 120 epochs </br>\n",
    "Model yang dihasilkan punya akurasi validasi (test) 74,9%. Nilai tersebut diperoleh pada epoch ke 69 </br>\n",
    "History dari training tidak disimpan </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> IMPORT LIBRARY </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tubes-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\tubes-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\tubes-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\tubes-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\tubes-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\tubes-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img \n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3914156753891776696\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3220452147\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8063702982043046726\n",
      "physical_device_desc: \"device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#Cek GPU yang akan dipakai\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(os.getcwd(), \"dataset-resized\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DATASET INPUT</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah dataset: 2527\n"
     ]
    }
   ],
   "source": [
    "path = \"dataset-resized\"\n",
    "listImage = glob.glob(os.path.join(path, '*/*.jpg'))\n",
    "print(\"Jumlah dataset: \" + str(len(listImage)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> IMAGE AUGMENTATION </h2>\n",
    "\n",
    "Membuat image augmentation pada dataset yang sudah ada untuk memperbanyak jumlah dataset</br>\n",
    "Membagi dataset yang ada menjadi dataset untuk training dan test </br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2276 images belonging to 6 classes.\n",
      "Found 251 images belonging to 6 classes.\n",
      "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n"
     ]
    }
   ],
   "source": [
    "train = ImageDataGenerator(horizontal_flip=True,\n",
    "                          vertical_flip=True,\n",
    "                          validation_split=0.1,\n",
    "                          rescale=1./255,\n",
    "                          shear_range=0.1,\n",
    "                          zoom_range=0.1,\n",
    "                          width_shift_range=0.1,\n",
    "                          height_shift_range=0.1)\n",
    "\n",
    "test = ImageDataGenerator(rescale=1/255, validation_split=0.1)\n",
    "\n",
    "train_generator = train.flow_from_directory(path, \n",
    "                                            target_size=(300,300),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            subset=\"training\")\n",
    "\n",
    "test_generator = test.flow_from_directory(path,\n",
    "                                          target_size=(300,300),\n",
    "                                          batch_size=32,\n",
    "                                          class_mode=\"categorical\",\n",
    "                                          subset=\"validation\")\n",
    "\n",
    "#label untuk image\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 300, 300, 3), (32, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for img,label in train_generator:\n",
    "    break\n",
    "img.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "with open('labels.txt', 'w') as file:\n",
    "    file.write(Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> CNN (Convolutional Neural Network) </h2>\n",
    "\n",
    "Membuat model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3), padding=\"same\", input_shape=(300,300,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "#menyimpan model\n",
    "modelFile = \"modelConfig.h5\"\n",
    "checkpoint1 = ModelCheckpoint(modelFile, monitor=\"val_acc\", verbose=1, save_best_only=True, mode=\"max\")\n",
    "callback_list = [checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 300, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 43808)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                2803776   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 2,843,910\n",
      "Trainable params: 2,843,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#konfigurasi model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TRAIN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.7203 - acc: 0.2408\n",
      "Epoch 00001: val_acc improved from -inf to 0.34263, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 97s 1s/step - loss: 1.7184 - acc: 0.2422 - val_loss: 1.5821 - val_acc: 0.3426\n",
      "Epoch 2/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.5750 - acc: 0.3349\n",
      "Epoch 00002: val_acc improved from 0.34263 to 0.37849, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 928ms/step - loss: 1.5725 - acc: 0.3369 - val_loss: 1.4993 - val_acc: 0.3785\n",
      "Epoch 3/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.4739 - acc: 0.3856\n",
      "Epoch 00003: val_acc improved from 0.37849 to 0.37849, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 929ms/step - loss: 1.4709 - acc: 0.3867 - val_loss: 1.5608 - val_acc: 0.3785\n",
      "Epoch 4/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.4002 - acc: 0.4322\n",
      "Epoch 00004: val_acc improved from 0.37849 to 0.43825, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 928ms/step - loss: 1.3974 - acc: 0.4336 - val_loss: 1.3854 - val_acc: 0.4382\n",
      "Epoch 5/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.4039 - acc: 0.4353\n",
      "Epoch 00005: val_acc improved from 0.43825 to 0.47410, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 931ms/step - loss: 1.4008 - acc: 0.4375 - val_loss: 1.3664 - val_acc: 0.4741\n",
      "Epoch 6/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.3280 - acc: 0.4767\n",
      "Epoch 00006: val_acc improved from 0.47410 to 0.49402, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 928ms/step - loss: 1.3340 - acc: 0.4761 - val_loss: 1.3795 - val_acc: 0.4940\n",
      "Epoch 7/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.3170 - acc: 0.4938\n",
      "Epoch 00007: val_acc did not improve from 0.49402\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 1.3156 - acc: 0.4938 - val_loss: 1.3367 - val_acc: 0.4542\n",
      "Epoch 8/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.2490 - acc: 0.5154\n",
      "Epoch 00008: val_acc improved from 0.49402 to 0.51793, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 929ms/step - loss: 1.2484 - acc: 0.5148 - val_loss: 1.2476 - val_acc: 0.5179\n",
      "Epoch 9/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.2098 - acc: 0.5290\n",
      "Epoch 00009: val_acc did not improve from 0.51793\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 1.2135 - acc: 0.5282 - val_loss: 1.2279 - val_acc: 0.5020\n",
      "Epoch 10/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.2402 - acc: 0.5282\n",
      "Epoch 00010: val_acc improved from 0.51793 to 0.52988, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 932ms/step - loss: 1.2400 - acc: 0.5294 - val_loss: 1.2804 - val_acc: 0.5299\n",
      "Epoch 11/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.1921 - acc: 0.5458\n",
      "Epoch 00011: val_acc improved from 0.52988 to 0.54183, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 928ms/step - loss: 1.1956 - acc: 0.5422 - val_loss: 1.2132 - val_acc: 0.5418\n",
      "Epoch 12/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.1563 - acc: 0.5603\n",
      "Epoch 00012: val_acc did not improve from 0.54183\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 1.1567 - acc: 0.5599 - val_loss: 1.1700 - val_acc: 0.5339\n",
      "Epoch 13/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.1766 - acc: 0.5440\n",
      "Epoch 00013: val_acc did not improve from 0.54183\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 1.1780 - acc: 0.5417 - val_loss: 1.3226 - val_acc: 0.4980\n",
      "Epoch 14/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.1394 - acc: 0.5704\n",
      "Epoch 00014: val_acc improved from 0.54183 to 0.54183, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 927ms/step - loss: 1.1388 - acc: 0.5712 - val_loss: 1.1531 - val_acc: 0.5418\n",
      "Epoch 15/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.1317 - acc: 0.5594\n",
      "Epoch 00015: val_acc did not improve from 0.54183\n",
      "72/71 [==============================] - 67s 927ms/step - loss: 1.1290 - acc: 0.5595 - val_loss: 1.2070 - val_acc: 0.5378\n",
      "Epoch 16/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0898 - acc: 0.5841\n",
      "Epoch 00016: val_acc did not improve from 0.54183\n",
      "72/71 [==============================] - 67s 925ms/step - loss: 1.0891 - acc: 0.5842 - val_loss: 1.2319 - val_acc: 0.5259\n",
      "Epoch 17/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0871 - acc: 0.5902\n",
      "Epoch 00017: val_acc improved from 0.54183 to 0.54582, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 927ms/step - loss: 1.0883 - acc: 0.5903 - val_loss: 1.1610 - val_acc: 0.5458\n",
      "Epoch 18/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0450 - acc: 0.6175\n",
      "Epoch 00018: val_acc improved from 0.54582 to 0.56972, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 929ms/step - loss: 1.0431 - acc: 0.6189 - val_loss: 1.0669 - val_acc: 0.5697\n",
      "Epoch 19/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0414 - acc: 0.6078\n",
      "Epoch 00019: val_acc did not improve from 0.56972\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 1.0422 - acc: 0.6077 - val_loss: 1.2394 - val_acc: 0.5458\n",
      "Epoch 20/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0772 - acc: 0.6030\n",
      "Epoch 00020: val_acc did not improve from 0.56972\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 1.0764 - acc: 0.6024 - val_loss: 1.1836 - val_acc: 0.5538\n",
      "Epoch 21/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0407 - acc: 0.6096\n",
      "Epoch 00021: val_acc did not improve from 0.56972\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 1.0447 - acc: 0.6085 - val_loss: 1.2037 - val_acc: 0.5498\n",
      "Epoch 22/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0171 - acc: 0.6254\n",
      "Epoch 00022: val_acc improved from 0.56972 to 0.58964, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 930ms/step - loss: 1.0144 - acc: 0.6272 - val_loss: 1.1263 - val_acc: 0.5896\n",
      "Epoch 23/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0115 - acc: 0.6140\n",
      "Epoch 00023: val_acc did not improve from 0.58964\n",
      "72/71 [==============================] - 67s 927ms/step - loss: 1.0112 - acc: 0.6159 - val_loss: 1.0748 - val_acc: 0.5857\n",
      "Epoch 24/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9780 - acc: 0.6408\n",
      "Epoch 00024: val_acc did not improve from 0.58964\n",
      "72/71 [==============================] - 67s 925ms/step - loss: 0.9795 - acc: 0.6406 - val_loss: 1.2181 - val_acc: 0.5259\n",
      "Epoch 25/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9854 - acc: 0.6232\n",
      "Epoch 00025: val_acc improved from 0.58964 to 0.59363, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 927ms/step - loss: 0.9821 - acc: 0.6254 - val_loss: 1.0780 - val_acc: 0.5936\n",
      "Epoch 26/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9837 - acc: 0.6435\n",
      "Epoch 00026: val_acc improved from 0.59363 to 0.60956, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 927ms/step - loss: 0.9845 - acc: 0.6436 - val_loss: 1.0573 - val_acc: 0.6096\n",
      "Epoch 27/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 1.0175 - acc: 0.6144\n",
      "Epoch 00027: val_acc did not improve from 0.60956\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 1.0162 - acc: 0.6155 - val_loss: 1.1377 - val_acc: 0.5857\n",
      "Epoch 28/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9471 - acc: 0.6536\n",
      "Epoch 00028: val_acc improved from 0.60956 to 0.62550, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 927ms/step - loss: 0.9450 - acc: 0.6545 - val_loss: 1.0198 - val_acc: 0.6255\n",
      "Epoch 29/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9530 - acc: 0.6545\n",
      "Epoch 00029: val_acc did not improve from 0.62550\n",
      "72/71 [==============================] - 67s 925ms/step - loss: 0.9569 - acc: 0.6558 - val_loss: 1.0567 - val_acc: 0.6135\n",
      "Epoch 30/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9409 - acc: 0.6501\n",
      "Epoch 00030: val_acc did not improve from 0.62550\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.9388 - acc: 0.6515 - val_loss: 1.0029 - val_acc: 0.6135\n",
      "Epoch 31/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9134 - acc: 0.6585\n",
      "Epoch 00031: val_acc did not improve from 0.62550\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.9065 - acc: 0.6611 - val_loss: 1.1191 - val_acc: 0.5817\n",
      "Epoch 32/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9080 - acc: 0.6756\n",
      "Epoch 00032: val_acc did not improve from 0.62550\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.9080 - acc: 0.6749 - val_loss: 1.0185 - val_acc: 0.6016\n",
      "Epoch 33/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8868 - acc: 0.6769\n",
      "Epoch 00033: val_acc did not improve from 0.62550\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.8866 - acc: 0.6784 - val_loss: 1.0591 - val_acc: 0.6056\n",
      "Epoch 34/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9013 - acc: 0.6624\n",
      "Epoch 00034: val_acc did not improve from 0.62550\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 0.8995 - acc: 0.6627 - val_loss: 1.0771 - val_acc: 0.5697\n",
      "Epoch 35/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8890 - acc: 0.6734\n",
      "Epoch 00035: val_acc improved from 0.62550 to 0.63745, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 925ms/step - loss: 0.8892 - acc: 0.6727 - val_loss: 1.0743 - val_acc: 0.6375\n",
      "Epoch 36/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.9083 - acc: 0.6690\n",
      "Epoch 00036: val_acc improved from 0.63745 to 0.66135, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 0.9073 - acc: 0.6697 - val_loss: 0.9741 - val_acc: 0.6614\n",
      "Epoch 37/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8238 - acc: 0.7064\n",
      "Epoch 00037: val_acc did not improve from 0.66135\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.8274 - acc: 0.7065 - val_loss: 0.9484 - val_acc: 0.6454\n",
      "Epoch 38/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8482 - acc: 0.6919\n",
      "Epoch 00038: val_acc did not improve from 0.66135\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.8466 - acc: 0.6927 - val_loss: 0.9683 - val_acc: 0.6375\n",
      "Epoch 39/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8555 - acc: 0.6897\n",
      "Epoch 00039: val_acc did not improve from 0.66135\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 0.8535 - acc: 0.6897 - val_loss: 0.9876 - val_acc: 0.6175\n",
      "Epoch 40/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8326 - acc: 0.6976\n",
      "Epoch 00040: val_acc improved from 0.66135 to 0.66932, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 0.8302 - acc: 0.6979 - val_loss: 0.9372 - val_acc: 0.6693\n",
      "Epoch 41/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8210 - acc: 0.6910\n",
      "Epoch 00041: val_acc improved from 0.66932 to 0.68526, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 925ms/step - loss: 0.8215 - acc: 0.6910 - val_loss: 0.9230 - val_acc: 0.6853\n",
      "Epoch 42/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8025 - acc: 0.7170\n",
      "Epoch 00042: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.8051 - acc: 0.7157 - val_loss: 0.9721 - val_acc: 0.6653\n",
      "Epoch 43/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8189 - acc: 0.7038\n",
      "Epoch 00043: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 67s 925ms/step - loss: 0.8220 - acc: 0.7032 - val_loss: 0.9403 - val_acc: 0.6614\n",
      "Epoch 44/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7732 - acc: 0.7262\n",
      "Epoch 00044: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.7786 - acc: 0.7239 - val_loss: 0.8978 - val_acc: 0.6773\n",
      "Epoch 45/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7847 - acc: 0.7240\n",
      "Epoch 00045: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.7873 - acc: 0.7227 - val_loss: 0.9383 - val_acc: 0.6733\n",
      "Epoch 46/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8010 - acc: 0.7091\n",
      "Epoch 00046: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.7999 - acc: 0.7096 - val_loss: 0.9338 - val_acc: 0.6454\n",
      "Epoch 47/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7909 - acc: 0.7086\n",
      "Epoch 00047: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.7907 - acc: 0.7092 - val_loss: 0.9101 - val_acc: 0.6653\n",
      "Epoch 48/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7908 - acc: 0.7104\n",
      "Epoch 00048: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.7910 - acc: 0.7087 - val_loss: 0.9142 - val_acc: 0.6653\n",
      "Epoch 49/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8018 - acc: 0.7099\n",
      "Epoch 00049: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.8028 - acc: 0.7092 - val_loss: 0.9279 - val_acc: 0.6614\n",
      "Epoch 50/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7778 - acc: 0.7152\n",
      "Epoch 00050: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.7811 - acc: 0.7144 - val_loss: 0.8661 - val_acc: 0.6574\n",
      "Epoch 51/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7925 - acc: 0.7170\n",
      "Epoch 00051: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.7930 - acc: 0.7179 - val_loss: 0.9729 - val_acc: 0.6494\n",
      "Epoch 52/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8075 - acc: 0.7099\n",
      "Epoch 00052: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.8067 - acc: 0.7105 - val_loss: 0.9495 - val_acc: 0.6295\n",
      "Epoch 53/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8078 - acc: 0.7020\n",
      "Epoch 00053: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.8068 - acc: 0.7027 - val_loss: 0.9290 - val_acc: 0.6534\n",
      "Epoch 54/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.8183 - acc: 0.7069\n",
      "Epoch 00054: val_acc did not improve from 0.68526\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.8204 - acc: 0.7057 - val_loss: 1.1071 - val_acc: 0.5737\n",
      "Epoch 55/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7908 - acc: 0.7170\n",
      "Epoch 00055: val_acc improved from 0.68526 to 0.68924, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 927ms/step - loss: 0.7886 - acc: 0.7170 - val_loss: 0.9312 - val_acc: 0.6892\n",
      "Epoch 56/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6972 - acc: 0.7443\n",
      "Epoch 00056: val_acc improved from 0.68924 to 0.71315, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 928ms/step - loss: 0.6963 - acc: 0.7447 - val_loss: 0.8801 - val_acc: 0.7131\n",
      "Epoch 57/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6891 - acc: 0.7469\n",
      "Epoch 00057: val_acc did not improve from 0.71315\n",
      "72/71 [==============================] - 66s 924ms/step - loss: 0.6894 - acc: 0.7461 - val_loss: 1.0405 - val_acc: 0.6255\n",
      "Epoch 58/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7459 - acc: 0.7183\n",
      "Epoch 00058: val_acc did not improve from 0.71315\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.7440 - acc: 0.7197 - val_loss: 0.9657 - val_acc: 0.6853\n",
      "Epoch 59/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.7460\n",
      "Epoch 00059: val_acc did not improve from 0.71315\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6922 - acc: 0.7461 - val_loss: 0.9042 - val_acc: 0.6972\n",
      "Epoch 60/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6967 - acc: 0.7421\n",
      "Epoch 00060: val_acc did not improve from 0.71315\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.6956 - acc: 0.7427 - val_loss: 0.8291 - val_acc: 0.6773\n",
      "Epoch 61/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6848 - acc: 0.7531\n",
      "Epoch 00061: val_acc improved from 0.71315 to 0.74104, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.6812 - acc: 0.7544 - val_loss: 0.8060 - val_acc: 0.7410\n",
      "Epoch 62/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7079 - acc: 0.7408\n",
      "Epoch 00062: val_acc did not improve from 0.74104\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.7098 - acc: 0.7396 - val_loss: 0.8753 - val_acc: 0.6733\n",
      "Epoch 63/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7661 - acc: 0.7284\n",
      "Epoch 00063: val_acc did not improve from 0.74104\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.7655 - acc: 0.7284 - val_loss: 0.9369 - val_acc: 0.6534\n",
      "Epoch 64/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6714 - acc: 0.7535\n",
      "Epoch 00064: val_acc did not improve from 0.74104\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6713 - acc: 0.7535 - val_loss: 0.8605 - val_acc: 0.7092\n",
      "Epoch 65/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7077 - acc: 0.7394\n",
      "Epoch 00065: val_acc did not improve from 0.74104\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.7091 - acc: 0.7383 - val_loss: 0.9796 - val_acc: 0.6574\n",
      "Epoch 66/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7407 - acc: 0.7337\n",
      "Epoch 00066: val_acc did not improve from 0.74104\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.7383 - acc: 0.7343 - val_loss: 0.8888 - val_acc: 0.7251\n",
      "Epoch 67/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6934 - acc: 0.7588\n",
      "Epoch 00067: val_acc did not improve from 0.74104\n",
      "72/71 [==============================] - 67s 924ms/step - loss: 0.6907 - acc: 0.7596 - val_loss: 0.8419 - val_acc: 0.6932\n",
      "Epoch 68/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6644 - acc: 0.7557\n",
      "Epoch 00068: val_acc did not improve from 0.74104\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6657 - acc: 0.7561 - val_loss: 0.8520 - val_acc: 0.6733\n",
      "Epoch 69/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6543 - acc: 0.7570\n",
      "Epoch 00069: val_acc improved from 0.74104 to 0.74900, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6561 - acc: 0.7552 - val_loss: 0.7534 - val_acc: 0.7490\n",
      "Epoch 70/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6384 - acc: 0.7672\n",
      "Epoch 00070: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 920ms/step - loss: 0.6333 - acc: 0.7704 - val_loss: 0.8002 - val_acc: 0.7291\n",
      "Epoch 71/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6694 - acc: 0.7592\n",
      "Epoch 00071: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6672 - acc: 0.7595 - val_loss: 0.9140 - val_acc: 0.6653\n",
      "Epoch 72/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6635 - acc: 0.7579\n",
      "Epoch 00072: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.6617 - acc: 0.7591 - val_loss: 0.8063 - val_acc: 0.7092\n",
      "Epoch 73/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6144 - acc: 0.7808\n",
      "Epoch 00073: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.6129 - acc: 0.7813 - val_loss: 1.0089 - val_acc: 0.6135\n",
      "Epoch 74/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6627 - acc: 0.7711\n",
      "Epoch 00074: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6624 - acc: 0.7708 - val_loss: 0.9003 - val_acc: 0.6614\n",
      "Epoch 75/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6276 - acc: 0.7755\n",
      "Epoch 00075: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.6255 - acc: 0.7769 - val_loss: 0.8242 - val_acc: 0.7371\n",
      "Epoch 76/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6736 - acc: 0.7491\n",
      "Epoch 00076: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.6708 - acc: 0.7501 - val_loss: 0.7479 - val_acc: 0.7012\n",
      "Epoch 77/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6128 - acc: 0.7777\n",
      "Epoch 00077: val_acc improved from 0.74900 to 0.74900, saving model to modelConfig.h5\n",
      "72/71 [==============================] - 67s 925ms/step - loss: 0.6136 - acc: 0.7783 - val_loss: 0.7462 - val_acc: 0.7490\n",
      "Epoch 78/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6326 - acc: 0.7755\n",
      "Epoch 00078: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6326 - acc: 0.7760 - val_loss: 0.8758 - val_acc: 0.6932\n",
      "Epoch 79/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7046 - acc: 0.7496\n",
      "Epoch 00079: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.7090 - acc: 0.7487 - val_loss: 0.8608 - val_acc: 0.7092\n",
      "Epoch 80/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6657 - acc: 0.7557\n",
      "Epoch 00080: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.6637 - acc: 0.7574 - val_loss: 0.8115 - val_acc: 0.7171\n",
      "Epoch 81/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6535 - acc: 0.7729\n",
      "Epoch 00081: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.6532 - acc: 0.7738 - val_loss: 0.8239 - val_acc: 0.6932\n",
      "Epoch 82/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.7874\n",
      "Epoch 00082: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 918ms/step - loss: 0.5975 - acc: 0.7903 - val_loss: 0.8070 - val_acc: 0.7092\n",
      "Epoch 83/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6307 - acc: 0.7768\n",
      "Epoch 00083: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.6277 - acc: 0.7782 - val_loss: 0.8616 - val_acc: 0.6972\n",
      "Epoch 84/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5934 - acc: 0.7870\n",
      "Epoch 00084: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 920ms/step - loss: 0.5965 - acc: 0.7851 - val_loss: 0.7914 - val_acc: 0.7490\n",
      "Epoch 85/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6584 - acc: 0.7663\n",
      "Epoch 00085: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 920ms/step - loss: 0.6589 - acc: 0.7661 - val_loss: 0.7816 - val_acc: 0.6972\n",
      "Epoch 86/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6062 - acc: 0.7870\n",
      "Epoch 00086: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6035 - acc: 0.7886 - val_loss: 0.9141 - val_acc: 0.6534\n",
      "Epoch 87/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5972 - acc: 0.7936\n",
      "Epoch 00087: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.6070 - acc: 0.7925 - val_loss: 0.7965 - val_acc: 0.7450\n",
      "Epoch 88/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6401 - acc: 0.7777\n",
      "Epoch 00088: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.6420 - acc: 0.7769 - val_loss: 0.9749 - val_acc: 0.6375\n",
      "Epoch 89/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6034 - acc: 0.7896\n",
      "Epoch 00089: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.6056 - acc: 0.7882 - val_loss: 0.9158 - val_acc: 0.6932\n",
      "Epoch 90/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5831 - acc: 0.7835\n",
      "Epoch 00090: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5836 - acc: 0.7834 - val_loss: 0.7828 - val_acc: 0.7052\n",
      "Epoch 91/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5882 - acc: 0.7927\n",
      "Epoch 00091: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.5905 - acc: 0.7930 - val_loss: 0.8704 - val_acc: 0.6733\n",
      "Epoch 92/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6211 - acc: 0.7760\n",
      "Epoch 00092: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.6204 - acc: 0.7757 - val_loss: 0.8036 - val_acc: 0.6892\n",
      "Epoch 93/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5531 - acc: 0.8002\n",
      "Epoch 00093: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.5490 - acc: 0.8020 - val_loss: 0.9615 - val_acc: 0.6853\n",
      "Epoch 94/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5518 - acc: 0.8033\n",
      "Epoch 00094: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 920ms/step - loss: 0.5504 - acc: 0.8038 - val_loss: 0.8961 - val_acc: 0.6932\n",
      "Epoch 95/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.6436 - acc: 0.7795\n",
      "Epoch 00095: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.6433 - acc: 0.7808 - val_loss: 0.9389 - val_acc: 0.6853\n",
      "Epoch 96/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.7033 - acc: 0.7575\n",
      "Epoch 00096: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.7007 - acc: 0.7582 - val_loss: 0.8308 - val_acc: 0.6892\n",
      "Epoch 97/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5892 - acc: 0.7874\n",
      "Epoch 00097: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.5856 - acc: 0.7891 - val_loss: 0.8350 - val_acc: 0.7291\n",
      "Epoch 98/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5453 - acc: 0.8085\n",
      "Epoch 00098: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5465 - acc: 0.8064 - val_loss: 0.8050 - val_acc: 0.7291\n",
      "Epoch 99/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5736 - acc: 0.7923\n",
      "Epoch 00099: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5716 - acc: 0.7929 - val_loss: 0.8082 - val_acc: 0.7012\n",
      "Epoch 100/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5567 - acc: 0.8112\n",
      "Epoch 00100: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5583 - acc: 0.8103 - val_loss: 0.8618 - val_acc: 0.7251\n",
      "Epoch 101/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5606 - acc: 0.7927\n",
      "Epoch 00101: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5650 - acc: 0.7908 - val_loss: 0.9736 - val_acc: 0.6813\n",
      "Epoch 102/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5591 - acc: 0.8015\n",
      "Epoch 00102: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.5611 - acc: 0.8012 - val_loss: 0.8791 - val_acc: 0.7291\n",
      "Epoch 103/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5350 - acc: 0.8085\n",
      "Epoch 00103: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.5326 - acc: 0.8090 - val_loss: 0.8648 - val_acc: 0.6892\n",
      "Epoch 104/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5693 - acc: 0.7918\n",
      "Epoch 00104: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5707 - acc: 0.7917 - val_loss: 1.0281 - val_acc: 0.6773\n",
      "Epoch 105/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5464 - acc: 0.8063\n",
      "Epoch 00105: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 920ms/step - loss: 0.5510 - acc: 0.8043 - val_loss: 1.0020 - val_acc: 0.6494\n",
      "Epoch 106/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5894 - acc: 0.7945\n",
      "Epoch 00106: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5915 - acc: 0.7942 - val_loss: 0.9122 - val_acc: 0.7331\n",
      "Epoch 107/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5402 - acc: 0.8094\n",
      "Epoch 00107: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5445 - acc: 0.8090 - val_loss: 0.8422 - val_acc: 0.7331\n",
      "Epoch 108/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5749 - acc: 0.8033\n",
      "Epoch 00108: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5754 - acc: 0.8030 - val_loss: 0.9030 - val_acc: 0.7052\n",
      "Epoch 109/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5160 - acc: 0.8107\n",
      "Epoch 00109: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.5158 - acc: 0.8116 - val_loss: 0.8258 - val_acc: 0.7291\n",
      "Epoch 110/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5255 - acc: 0.8002\n",
      "Epoch 00110: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.5244 - acc: 0.8008 - val_loss: 0.9067 - val_acc: 0.7371\n",
      "Epoch 111/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5024 - acc: 0.8305\n",
      "Epoch 00111: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.5050 - acc: 0.8298 - val_loss: 0.9290 - val_acc: 0.7291\n",
      "Epoch 112/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5323 - acc: 0.8169\n",
      "Epoch 00112: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5327 - acc: 0.8168 - val_loss: 1.0381 - val_acc: 0.7131\n",
      "Epoch 113/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5446 - acc: 0.8160\n",
      "Epoch 00113: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 924ms/step - loss: 0.5431 - acc: 0.8168 - val_loss: 0.8410 - val_acc: 0.7092\n",
      "Epoch 114/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5049 - acc: 0.8094\n",
      "Epoch 00114: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 924ms/step - loss: 0.5029 - acc: 0.8103 - val_loss: 0.8833 - val_acc: 0.7211\n",
      "Epoch 115/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5219 - acc: 0.8138\n",
      "Epoch 00115: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 923ms/step - loss: 0.5234 - acc: 0.8142 - val_loss: 0.9566 - val_acc: 0.6853\n",
      "Epoch 116/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5110 - acc: 0.8195\n",
      "Epoch 00116: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5149 - acc: 0.8178 - val_loss: 0.8751 - val_acc: 0.7171\n",
      "Epoch 117/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5576 - acc: 0.8059\n",
      "Epoch 00117: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.5602 - acc: 0.8047 - val_loss: 0.8588 - val_acc: 0.7490\n",
      "Epoch 118/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5098 - acc: 0.8094\n",
      "Epoch 00118: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 921ms/step - loss: 0.5130 - acc: 0.8091 - val_loss: 0.8747 - val_acc: 0.7211\n",
      "Epoch 119/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.8217\n",
      "Epoch 00119: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 67s 926ms/step - loss: 0.5220 - acc: 0.8216 - val_loss: 0.7739 - val_acc: 0.7291\n",
      "Epoch 120/120\n",
      "71/71 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.8112\n",
      "Epoch 00120: val_acc did not improve from 0.74900\n",
      "72/71 [==============================] - 66s 922ms/step - loss: 0.5195 - acc: 0.8116 - val_loss: 0.7881 - val_acc: 0.7171\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=120,\n",
    "                              steps_per_epoch=2276/32,\n",
    "                              validation_data=test_generator,\n",
    "                              validation_steps=251/32,\n",
    "                              workers=4,\n",
    "                              callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU",
   "language": "python",
   "name": "tubes-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
